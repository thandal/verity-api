{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verity Cloud API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "VERITY_API_URL = \"https://us-central1-verity-exam.cloudfunctions.net/\"\n",
    "\n",
    "# From the profile page in Verity, click on \"API Key\", then paste it here.\n",
    "API_KEY = \"eyhjbGcaklaj3ovkg.2wij3uiwiblahblahblah\"\n",
    "\n",
    "def cloudFunction(name, data={}):\n",
    "  r = requests.post(VERITY_API_URL + name,\n",
    "                    headers={\n",
    "                      'Content-Type': 'application/json',\n",
    "                      'Authorization': 'Bearer ' + VERITY_API_KEY,\n",
    "                    },\n",
    "                    json={\"data\": data},\n",
    "                    )\n",
    "  #print(r)\n",
    "  j = r.json()\n",
    "  #print(j)\n",
    "  return j['result']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual step-by-step example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examSpecs = cloudFunction('searchExamSpecs')\n",
    "print(f\"{examSpecs=}\")\n",
    "print(f\"{examSpecs.keys()=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examSpecId = \"-NF_H1\"\n",
    "examExecId = cloudFunction('startExam', data={\"exam_spec_id\": examSpecId})\n",
    "print(f\"{examExecId=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responseId, questionText = cloudFunction('getQuestion', data={\"exam_exec_id\": examExecId})\n",
    "print(f\"{responseId=}\")\n",
    "print(f\"{questionText=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cloudFunction('submitResponse', data={\"exam_exec_id\": examExecId, \"response_id\": responseId, \"response_text\": \"The name of the three-headed dog that guards the underworld is Cerberus.\"})\n",
    "print(f\"{score=}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local student model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load local huggingface model\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "MODEL_NAME = \"gpt2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, padding_side=\"left\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, device_map=\"auto\")\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "print(f\"Loaded {MODEL_NAME=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete(prompt, n=1, engine=None, max_tokens=40, logprobs=None, logit_bias=None, temperature=0.7):\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to('cuda')\n",
    "    generated_ids = model.generate(input_ids, do_sample=True, max_new_tokens=max_tokens, num_return_sequences=n, use_cache=False, temperature=temperature)\n",
    "    c = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "    \n",
    "    # Clean up the output (may need to be customized for various models...)\n",
    "    c = [x[len(prompt):] for x in c]  # Skip the prompt\n",
    "    c = [x.strip() for x in c]  # Trim whitespace from the ends\n",
    "    c = [x.split('\\n')[0] for x in c]    # Stop at the first stop character -- TODO: figure out how to truncate generation!!!\n",
    "    c = [x.strip() for x in c]   # Strip whitespace\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud student model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import tenacity\n",
    "\n",
    "MODEL_API_URL = 'https://api.openai.com/v1/'\n",
    "MODEL_API_KEY = 'sk-YOUR_OPEN_AI_KEY'\n",
    "\n",
    "## Standard OpenAI-style query\n",
    "#def complete(prompt, n=1, engine='davinci', max_tokens=20, temperature=0.0, logprobs=None, logit_bias={}):\n",
    "#    r = requests.post(MODEL_API_URL + 'engines/' + engine + '/completions',\n",
    "#                      headers={\n",
    "#                        'Content-Type': 'application/json',\n",
    "#                        'Authorization': 'Bearer ' + MODEL_API_KEY,\n",
    "#                      },\n",
    "#                      json={\n",
    "#                        'prompt': prompt,\n",
    "#                        'max_tokens': max_tokens,\n",
    "#                        'stop': '\\n',\n",
    "#                        'n': n,\n",
    "#                        'temperature': temperature,\n",
    "#                        'logprobs': logprobs,\n",
    "#                        'logit_bias': logit_bias,\n",
    "#                      })\n",
    "#    j = r.json()\n",
    "#    #print(j)\n",
    "#    return [c['text'] for c in j['choices']]\n",
    "\n",
    "@tenacity.retry(wait=tenacity.wait_random_exponential(min=1, max=20), stop=tenacity.stop_after_attempt(3))\n",
    "def chatComplete(messages, n=1, engine='gpt-3.5-turbo', max_tokens=20, temperature=0.7):\n",
    "    r = requests.post(API_URL + 'chat/completions',\n",
    "                      headers={\n",
    "                        'Content-Type': 'application/json',\n",
    "                        'Authorization': 'Bearer ' + API_KEY,\n",
    "                      },\n",
    "                      json={\n",
    "                        'model': engine,\n",
    "                        'messages': messages,\n",
    "                        'max_tokens': max_tokens,\n",
    "                        'n': n,\n",
    "                        'temperature': temperature,\n",
    "                      })\n",
    "    j = r.json()\n",
    "    print(j)\n",
    "    #print(j['choices'])\n",
    "    return [c['message']['content'] for c in j['choices']]\n",
    "\n",
    "def complete(prompt, n=1, max_tokens=20, temperature=0.7):\n",
    "    return chatComplete([{\"role\": \"system\", \"content\": prompt}], n=1, max_tokens=max_tokens, temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated exam taking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete(\"Q: How many ounces in a pound.\\nA:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exams to take\n",
    "examSpecIds = [\n",
    "    '-NF_H1',                # Greek mythology\n",
    "    '-NYry2Ic0-WhbvgiiSh2',  # Sailing small boats\n",
    "    '-NF_T1',                # Pokemon \n",
    "]  \n",
    "\n",
    "for examSpecId in examSpecIds:\n",
    "    examExecId = cloudFunction('startExam', data={\"exam_spec_id\": examSpecId})\n",
    "    while True:\n",
    "        responseId, questionText = cloudFunction('getQuestion', data={\"exam_exec_id\": examExecId})\n",
    "        if responseId == 'COMPLETED':\n",
    "            print(\"Total score:\", questionText)\n",
    "            break\n",
    "        prompt = \"\"\n",
    "        prompt += \"You are a student taking an exam. Please respond clearly and accurately to the following question, and provide supporting details when possible.\\n\"\n",
    "        prompt += \"Question: \" + questionText + \"\\n\"\n",
    "        prompt += \"Answer:\"\n",
    "        print(f\"{prompt=}\")\n",
    "        response = complete(prompt)[0]\n",
    "        print(f\"{response=}\")\n",
    "        score = cloudFunction('submitResponse', data={\"exam_exec_id\": examExecId, \"response_id\": responseId, \"response_text\": response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
